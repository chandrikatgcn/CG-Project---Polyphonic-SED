{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import os\n",
    "import numpy as np\n",
    "import time\n",
    "import sys\n",
    "import matplotlib.pyplot as plot\n",
    "from keras.layers import Bidirectional, TimeDistributed, Conv2D, MaxPooling2D, Input, GRU, Dense, Activation, Dropout, Reshape, Permute\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.models import Model\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from IPython import embed\n",
    "import keras.backend as K\n",
    "K.set_image_data_format('channels_first')\n",
    "plot.switch_backend('agg')\n",
    "sys.setrecursionlimit(10000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_data(_feat_folder, _mono, _fold=None):\n",
    "    feat_file_fold = os.path.join(_feat_folder, 'mbe_{}_fold{}.npz'.format('mon' if _mono else 'bin', _fold))\n",
    "    dmp = np.load(feat_file_fold)\n",
    "    _X_train, _Y_train, _X_test, _Y_test = dmp['arr_0'],  dmp['arr_1'],  dmp['arr_2'],  dmp['arr_3']\n",
    "    return _X_train, _Y_train, _X_test, _Y_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_model(data_in, data_out, _cnn_nb_filt, _cnn_pool_size, _rnn_nb, _fc_nb):\n",
    "\n",
    "    spec_start = Input(shape=(data_in.shape[-3], data_in.shape[-2], data_in.shape[-1]))\n",
    "    spec_x = spec_start\n",
    "    for _i, _cnt in enumerate(_cnn_pool_size):\n",
    "        spec_x = Conv2D(filters=_cnn_nb_filt, kernel_size=(3, 3), padding='same')(spec_x)\n",
    "        spec_x = BatchNormalization(axis=1)(spec_x)\n",
    "        spec_x = Activation('relu')(spec_x)\n",
    "        spec_x = MaxPooling2D(pool_size=(1, _cnn_pool_size[_i]))(spec_x)\n",
    "        spec_x = Dropout(dropout_rate)(spec_x)\n",
    "    spec_x = Permute((2, 1, 3))(spec_x)\n",
    "    spec_x = Reshape((data_in.shape[-2], -1))(spec_x)\n",
    "\n",
    "    for _r in _rnn_nb:\n",
    "        spec_x = Bidirectional(\n",
    "            GRU(_r, activation='tanh', dropout=dropout_rate, recurrent_dropout=dropout_rate, return_sequences=True),\n",
    "            merge_mode='mul')(spec_x)\n",
    "\n",
    "    for _f in _fc_nb:\n",
    "        spec_x = TimeDistributed(Dense(_f))(spec_x)\n",
    "        spec_x = Dropout(dropout_rate)(spec_x)\n",
    "\n",
    "    spec_x = TimeDistributed(Dense(data_out.shape[-1]))(spec_x)\n",
    "    out = Activation('sigmoid', name='strong_out')(spec_x)\n",
    "\n",
    "    _model = Model(inputs=spec_start, outputs=out)\n",
    "    _model.compile(optimizer='Adam', loss='binary_crossentropy')\n",
    "    _model.summary()\n",
    "    return _model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_functions(_nb_epoch, _tr_loss, _val_loss, _f1, _er, extension=''):\n",
    "    plot.figure()\n",
    "\n",
    "    plot.subplot(211)\n",
    "    plot.plot(range(_nb_epoch), _tr_loss, label='train loss')\n",
    "    plot.plot(range(_nb_epoch), _val_loss, label='val loss')\n",
    "    plot.legend()\n",
    "    plot.grid(True)\n",
    "\n",
    "    plot.subplot(212)\n",
    "    plot.plot(range(_nb_epoch), _f1, label='f')\n",
    "    plot.plot(range(_nb_epoch), _er, label='er')\n",
    "    plot.legend()\n",
    "    plot.grid(True)\n",
    "\n",
    "    plot.savefig(__models_dir + __fig_name + extension)\n",
    "    plot.close()\n",
    "    print('figure name : {}'.format(__fig_name))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def reshape_3Dto2D(A):\n",
    "    return A.reshape(A.shape[0] * A.shape[1], A.shape[2])\n",
    "\n",
    "\n",
    "def split_multi_channels(data, num_channels):\n",
    "    in_shape = data.shape\n",
    "    if len(in_shape) == 3:\n",
    "        hop = in_shape[2] / num_channels\n",
    "        tmp = np.zeros((in_shape[0], num_channels, in_shape[1], hop))\n",
    "        for i in range(num_channels):\n",
    "            tmp[:, i, :, :] = data[:, :, i * hop:(i + 1) * hop]\n",
    "    else:\n",
    "        print(\"ERROR: The input should be a 3D matrix but it seems to have dimensions \", in_shape)\n",
    "        exit()\n",
    "    return tmp\n",
    "\n",
    "\n",
    "def split_in_seqs(data, subdivs):\n",
    "    if len(data.shape) == 1:\n",
    "        if data.shape[0] % subdivs:\n",
    "            data = data[:-(data.shape[0] % subdivs), :]\n",
    "        data = data.reshape((data.shape[0] / subdivs, subdivs, 1))\n",
    "    elif len(data.shape) == 2:\n",
    "        if data.shape[0] % subdivs:\n",
    "            data = data[:-(data.shape[0] % subdivs), :]\n",
    "        data = data.reshape((data.shape[0] / subdivs, subdivs, data.shape[1]))\n",
    "    elif len(data.shape) == 3:\n",
    "        if data.shape[0] % subdivs:\n",
    "            data = data[:-(data.shape[0] % subdivs), :, :]\n",
    "        data = data.reshape((data.shape[0] / subdivs, subdivs, data.shape[1], data.shape[2]))\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preprocess_data(_X, _Y, _X_test, _Y_test, _seq_len, _nb_ch):\n",
    "    # split into sequences\n",
    "    _X = split_in_seqs(_X, _seq_len)\n",
    "    _Y = split_in_seqs(_Y, _seq_len)\n",
    "\n",
    "    _X_test = split_in_seqs(_X_test, _seq_len)\n",
    "    _Y_test = split_in_seqs(_Y_test, _seq_len)\n",
    "\n",
    "    _X = split_multi_channels(_X, _nb_ch)\n",
    "    _X_test = split_multi_channels(_X_test, _nb_ch)\n",
    "    return _X, _Y, _X_test, _Y_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#######################################################################################\n",
    "# MAIN SCRIPT STARTS HERE\n",
    "#######################################################################################\n",
    "\n",
    "is_mono = False  # True: mono-channel input, False: binaural input\n",
    "\n",
    "feat_folder = '/media/manjunath/BCE0E709E0E6C8AA/Evaluation-data/DCASE2017/feat/'\n",
    "__fig_name = '{}_{}'.format('mon' if is_mono else 'bin', time.strftime(\"%Y_%m_%d_%H_%M_%S\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nb_ch = 1 if is_mono else 2\n",
    "batch_size = 128    # Decrease this if you want to run on smaller GPU's\n",
    "seq_len = 256       # Frame sequence length. Input to the CRNN.\n",
    "nb_epoch = 500      # Training epochs\n",
    "patience = int(0.25 * nb_epoch)  # Patience for early stopping\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "UNIQUE ID: bin_2018_08_03_15_37_37\n",
      "TRAINING PARAMETERS: nb_ch: 2, seq_len: 256, batch_size: 128, nb_epoch: 500, frames_1_sec: 43\n"
     ]
    }
   ],
   "source": [
    "# Number of frames in 1 second, required to calculate F and ER for 1 sec segments.\n",
    "# Make sure the nfft and sr are the same as in feature.py\n",
    "sr = 44100\n",
    "nfft = 2048\n",
    "frames_1_sec = int(sr/(nfft/2.0))\n",
    "\n",
    "print('\\n\\nUNIQUE ID: {}'.format(__fig_name))\n",
    "print('TRAINING PARAMETERS: nb_ch: {}, seq_len: {}, batch_size: {}, nb_epoch: {}, frames_1_sec: {}'.format(\n",
    "    nb_ch, seq_len, batch_size, nb_epoch, frames_1_sec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def CreateFolder( fd ):\n",
    "    if not os.path.exists(fd):\n",
    "        os.makedirs(fd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Folder for saving model and training curves\n",
    "__models_dir = '/media/manjunath/BCE0E709E0E6C8AA/Evaluation-data/DCASE2017/model/'\n",
    "CreateFolder(__models_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MODEL PARAMETERS:\n",
      " cnn_nb_filt: 128, cnn_pool_size: [5, 2, 2], rnn_nb: [32, 32], fc_nb: [32], dropout_rate: 0.5\n"
     ]
    }
   ],
   "source": [
    "# CRNN model definition\n",
    "cnn_nb_filt = 128            # CNN filter size\n",
    "cnn_pool_size = [5, 2, 2]   # Maxpooling across frequency. Length of cnn_pool_size =  number of CNN layers\n",
    "rnn_nb = [32, 32]           # Number of RNN nodes.  Length of rnn_nb =  number of RNN layers\n",
    "fc_nb = [32]                # Number of FC nodes.  Length of fc_nb =  number of FC layers\n",
    "dropout_rate = 0.5          # Dropout after each layer\n",
    "print('MODEL PARAMETERS:\\n cnn_nb_filt: {}, cnn_pool_size: {}, rnn_nb: {}, fc_nb: {}, dropout_rate: {}'.format(\n",
    "    cnn_nb_filt, cnn_pool_size, rnn_nb, fc_nb, dropout_rate))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(254, 2, 256, 40) (254, 2, 256, 40)\n"
     ]
    }
   ],
   "source": [
    "avg_er = list()\n",
    "avg_f1 = list()\n",
    "fold=1\n",
    " # Load feature and labels, pre-process it\n",
    "X, Y, X_test, Y_test = load_data(feat_folder, is_mono, fold)\n",
    "X, Y, X_test, Y_test = preprocess_data(X, Y, X_test, Y_test, seq_len, nb_ch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 2, 256, 40)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 128, 256, 40)      2432      \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 128, 256, 40)      512       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 128, 256, 40)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 128, 256, 8)       0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 128, 256, 8)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 128, 256, 8)       147584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 128, 256, 8)       512       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 128, 256, 8)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 128, 256, 4)       0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 128, 256, 4)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 128, 256, 4)       147584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 128, 256, 4)       512       \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 128, 256, 4)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 128, 256, 2)       0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 128, 256, 2)       0         \n",
      "_________________________________________________________________\n",
      "permute_1 (Permute)          (None, 256, 128, 2)       0         \n",
      "_________________________________________________________________\n",
      "reshape_1 (Reshape)          (None, 256, 256)          0         \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 256, 32)           55488     \n",
      "_________________________________________________________________\n",
      "bidirectional_2 (Bidirection (None, 256, 32)           12480     \n",
      "_________________________________________________________________\n",
      "time_distributed_1 (TimeDist (None, 256, 32)           1056      \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 256, 32)           0         \n",
      "_________________________________________________________________\n",
      "time_distributed_2 (TimeDist (None, 256, 11)           363       \n",
      "_________________________________________________________________\n",
      "strong_out (Activation)      (None, 256, 11)           0         \n",
      "=================================================================\n",
      "Total params: 368,523\n",
      "Trainable params: 367,755\n",
      "Non-trainable params: 768\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    " # Load model\n",
    "model = get_model(X, Y, cnn_nb_filt, cnn_pool_size, rnn_nb, fc_nb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Training\n",
    "best_epoch, pat_cnt, best_er, f1_for_best_er, best_conf_mat = 0, 0, 99999, None, None\n",
    "tr_loss, val_loss, f1_overall_1sec_list, er_overall_1sec_list = [0] * nb_epoch, [0] * nb_epoch, [0] * nb_epoch, [0] * nb_epoch\n",
    "posterior_thresh = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 0 Train on 254 samples, validate on 111 samples\n",
      "Epoch 1/1\n",
      "211s - loss: 0.6955 - val_loss: 0.6911\n",
      "Epoch : 1 Train on 254 samples, validate on 111 samples\n",
      "Epoch 1/1\n"
     ]
    }
   ],
   "source": [
    "for i in range(nb_epoch):\n",
    "        print('Epoch : {} '.format(i), end='')\n",
    "        hist = model.fit(\n",
    "            X, Y,\n",
    "            batch_size=batch_size,\n",
    "            validation_data=[X_test, Y_test],\n",
    "            epochs=1,\n",
    "            verbose=2\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "val_loss[i] = hist.history.get('val_loss')[-1]\n",
    "        tr_loss[i] = hist.history.get('loss')[-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "#####################\n",
    "# Scoring functions\n",
    "#\n",
    "# Code blocks taken from Toni Heittola's repository: http://tut-arg.github.io/sed_eval/\n",
    "#\n",
    "# Implementation of the Metrics in the following paper:\n",
    "# Annamaria Mesaros, Toni Heittola, and Tuomas Virtanen, 'Metrics for polyphonic sound event detection',\n",
    "# Applied Sciences, 6(6):162, 2016\n",
    "#####################\n",
    "eps = np.finfo(np.float).eps\n",
    "\n",
    "def f1_overall_framewise(O, T):\n",
    "    if len(O.shape) == 3:\n",
    "        O, T = reshape_3Dto2D(O), reshape_3Dto2D(T)\n",
    "    TP = ((2 * T - O) == 1).sum()\n",
    "    Nref, Nsys = T.sum(), O.sum()\n",
    "\n",
    "    prec = float(TP) / float(Nsys + eps)\n",
    "    recall = float(TP) / float(Nref + eps)\n",
    "    f1_score = 2 * prec * recall / (prec + recall + utils.eps)\n",
    "    return f1_score\n",
    "\n",
    "\n",
    "def er_overall_framewise(O, T):\n",
    "    if len(O.shape) == 3:\n",
    "        O, T = reshape_3Dto2D(O), reshape_3Dto2D(T)\n",
    "    TP = ((2 * T - O) == 1).sum()\n",
    "    Nref, Nsys = T.sum(), O.sum()\n",
    "    ER = (max(Nref, Nsys) - TP) / (Nref + 0.0)\n",
    "    return ER\n",
    "\n",
    "\n",
    "def f1_overall_1sec(O, T, block_size):\n",
    "    if len(O.shape) == 3:\n",
    "        O, T = reshape_3Dto2D(O), reshape_3Dto2D(T)\n",
    "    new_size = int(np.ceil(O.shape[0] / block_size))\n",
    "    O_block = np.zeros((new_size, O.shape[1]))\n",
    "    T_block = np.zeros((new_size, O.shape[1]))\n",
    "    for i in range(0, new_size):\n",
    "        O_block[i, :] = np.max(O[int(i * block_size):int(i * block_size + block_size - 1), ], axis=0)\n",
    "        T_block[i, :] = np.max(T[int(i * block_size):int(i * block_size + block_size - 1), ], axis=0)\n",
    "    return f1_overall_framewise(O_block, T_block)\n",
    "\n",
    "\n",
    "def er_overall_1sec(O, T, block_size):\n",
    "    if len(O.shape) == 3:\n",
    "        O, T = reshape_3Dto2D(O), reshape_3Dto2D(T)\n",
    "    new_size = int(O.shape[0] / block_size)\n",
    "    O_block = np.zeros((new_size, O.shape[1]))\n",
    "    T_block = np.zeros((new_size, O.shape[1]))\n",
    "    for i in range(0, new_size):\n",
    "        O_block[i, :] = np.max(O[int(i * block_size):int(i * block_size + block_size - 1), ], axis=0)\n",
    "        T_block[i, :] = np.max(T[int(i * block_size):int(i * block_size + block_size - 1), ], axis=0)\n",
    "    return er_overall_framewise(O_block, T_block)\n",
    "\n",
    "\n",
    "def compute_scores(pred, y, frames_in_1_sec=50):\n",
    "    scores = dict()\n",
    "    scores['f1_overall_1sec'] = f1_overall_1sec(pred, y, frames_in_1_sec)\n",
    "    scores['er_overall_1sec'] = er_overall_1sec(pred, y, frames_in_1_sec)\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    " # Calculate the predictions on test data, in order to calculate ER and F scores\n",
    "pred = model.predict(X_test)\n",
    "pred_thresh = pred > posterior_thresh\n",
    "score_list = compute_scores(pred_thresh, Y_test, frames_in_1_sec=frames_1_sec)\n",
    "f1_overall_1sec_list[i] = score_list['f1_overall_1sec']\n",
    "er_overall_1sec_list[i] = score_list['er_overall_1sec']\n",
    "pat_cnt = pat_cnt + 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    " # Calculate confusion matrix\n",
    "test_pred_cnt = np.sum(pred_thresh, 2)\n",
    "Y_test_cnt = np.sum(Y_test, 2)\n",
    "conf_mat = confusion_matrix(Y_test_cnt.reshape(-1), test_pred_cnt.reshape(-1))\n",
    "conf_mat = conf_mat / (eps + np.sum(conf_mat, 1)[:, None].astype('float'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if er_overall_1sec_list[i] < best_er:\n",
    "            best_conf_mat = conf_mat\n",
    "            best_er = er_overall_1sec_list[i]\n",
    "            f1_for_best_er = f1_overall_1sec_list[i]\n",
    "            model.save(os.path.join(__models_dir, '{}_fold_{}_model.h5'.format(__fig_name, fold)))\n",
    "            best_epoch = i\n",
    "            pat_cnt = 0\n",
    "\n",
    "print('tr Er : {}, val Er : {}, F1_overall : {}, ER_overall : {} Best ER : {}, best_epoch: {}'.format(\n",
    "                tr_loss[i], val_loss[i], f1_overall_1sec_list[i], er_overall_1sec_list[i], best_er, best_epoch))\n",
    "plot_functions(nb_epoch, tr_loss, val_loss, f1_overall_1sec_list, er_overall_1sec_list, '_fold_{}'.format(fold))\n",
    "if pat_cnt > patience:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print('tr Er : {}, val Er : {}, F1_overall : {}, ER_overall : {} Best ER : {}, best_epoch: {}'.format(\n",
    "                tr_loss[i], val_loss[i], f1_overall_1sec_list[i], er_overall_1sec_list[i], best_er, best_epoch))\n",
    "plot_functions(nb_epoch, tr_loss, val_loss, f1_overall_1sec_list, er_overall_1sec_list, '_fold_{}'.format(fold))\n",
    "    if pat_cnt > patience:\n",
    "        break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
